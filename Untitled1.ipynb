{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH2eeSF91eiw",
        "outputId": "00555684-b5fd-484b-b035-eb631ccc28bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.151.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client openai pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "def load_csv(file):\n",
        "    # Ensure file is uploaded before attempting to read it\n",
        "    if file is None:\n",
        "        return None, gr.Dropdown.update(choices=[])\n",
        "\n",
        "    try:\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(file.name)\n",
        "        columns = df.columns.tolist()\n",
        "\n",
        "        # Display the first few rows for preview (convert to JSON for Gradio compatibility)\n",
        "        data_preview = df.head(10).to_dict()  # Show first 10 rows for preview\n",
        "\n",
        "        # Update the data preview and column dropdown\n",
        "        return data_preview, gr.Dropdown.update(choices=columns)\n",
        "    except Exception as e:\n",
        "        # If there's an error reading the CSV, display the error message\n",
        "        return str(e), gr.Dropdown.update(choices=[])\n",
        "\n",
        "def parse_column_with_llm(df_json, selected_column):\n",
        "    try:\n",
        "        # Convert JSON back to a dataframe\n",
        "        df = pd.DataFrame(df_json)\n",
        "\n",
        "        if selected_column not in df.columns:\n",
        "            return \"No column selected.\", None, None\n",
        "\n",
        "        # Extract summary information (placeholder for LLM processing if available)\n",
        "        column_data = df[selected_column]\n",
        "        summary = column_data.describe().to_frame().to_string()\n",
        "\n",
        "        # Plot the selected column's data (histogram and boxplot for numeric data)\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "        column_data.plot(kind='hist', ax=ax1, title=f\"{selected_column} Histogram\", color='skyblue')\n",
        "        column_data.plot(kind='box', ax=ax2, title=f\"{selected_column} Boxplot\")\n",
        "\n",
        "        # Save the plot as an image in memory\n",
        "        output_file = BytesIO()\n",
        "        fig.savefig(output_file, format=\"png\")\n",
        "        output_file.seek(0)\n",
        "\n",
        "        # Save the summary to a file for download\n",
        "        summary_file_path = \"/mnt/data/parsed_column_info.txt\"\n",
        "        with open(summary_file_path, \"w\") as f:\n",
        "            f.write(f\"Summary of '{selected_column}':\\n\\n{summary}\")\n",
        "\n",
        "        plt.close(fig)  # Close the figure to free memory\n",
        "        return summary, output_file, summary_file_path\n",
        "    except Exception as e:\n",
        "        return str(e), None, None\n",
        "\n",
        "# Set up Gradio interface\n",
        "with gr.Blocks() as dashboard:\n",
        "    gr.Markdown(\"### AI-powered Data Analysis and Extraction Dashboard\")\n",
        "\n",
        "    # Step 1: File Upload and Column Selection\n",
        "    file_input = gr.File(label=\"Upload CSV File\")\n",
        "    data_preview = gr.Dataframe(label=\"Data Preview\", interactive=False)\n",
        "    column_select = gr.Dropdown(label=\"Select the Column to Analyze\", choices=[])\n",
        "\n",
        "    # Step 2: Process Selected Column\n",
        "    summary_output = gr.Textbox(label=\"Summary Information\")\n",
        "    graph_output = gr.Image(label=\"Data Visualization\")\n",
        "    download_button = gr.File(label=\"Download Summary File\")\n",
        "\n",
        "    # Actions to load data and update column selection dropdown\n",
        "    file_input.change(load_csv, inputs=file_input, outputs=[data_preview, column_select])\n",
        "    column_select.change(parse_column_with_llm, inputs=[data_preview, column_select], outputs=[summary_output, graph_output, download_button])\n",
        "\n",
        "dashboard.launch()\n"
      ],
      "metadata": {
        "id": "ZPCJly_kOPfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "87327fda-66e5-438a-bc95-3928a3b135e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8a19dc1b14d0815d4e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8a19dc1b14d0815d4e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "# Step 1: Load CSV File\n",
        "def load_csv(file_path):\n",
        "    \"\"\"Load the CSV file and preview the first few rows.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"Dataset Preview:\")\n",
        "    print(df.head())\n",
        "    return df\n",
        "\n",
        "# Step 2: Select Column and Analyze\n",
        "def parse_column_with_llm(df, selected_column):\n",
        "    \"\"\"Analyze the selected column and return a summary and plots.\"\"\"\n",
        "    if selected_column not in df.columns:\n",
        "        return \"Error: Column not found in dataset.\", None\n",
        "\n",
        "    # Get summary statistics (placeholder for LLM if needed)\n",
        "    column_data = df[selected_column]\n",
        "    summary = column_data.describe().to_frame().to_string()\n",
        "    print(f\"\\nSummary of '{selected_column}':\\n{summary}\")\n",
        "\n",
        "    # Check if the column is numeric before plotting\n",
        "    if pd.api.types.is_numeric_dtype(column_data):\n",
        "        # Plot histogram and boxplot for numeric data\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "        column_data.plot(kind='hist', ax=ax1, title=f\"{selected_column} Histogram\", color='skyblue')\n",
        "        column_data.plot(kind='box', ax=ax2, title=f\"{selected_column} Boxplot\")\n",
        "\n",
        "        # Save the figure\n",
        "        plot_file = \"column_plots.png\"  # Saves in the current directory\n",
        "        fig.savefig(plot_file)\n",
        "        plt.close(fig)  # Free up memory\n",
        "    else:\n",
        "        # Skip plotting if data is non-numeric\n",
        "        plot_file = None\n",
        "        print(f\"\\nColumn '{selected_column}' is not numeric. Skipping plots.\")\n",
        "\n",
        "    # Save summary to a text file\n",
        "    summary_file = \"column_summary.txt\"  # Saves in the current directory\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        f.write(f\"Summary of '{selected_column}':\\n\\n{summary}\")\n",
        "\n",
        "    print(\"\\nSummary and visualization saved successfully.\")\n",
        "    return summary, plot_file, summary_file\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # File path for the CSV file\n",
        "    file_path = \"/content/apple_quality.csv\"\n",
        "\n",
        "    # Load dataset and preview\n",
        "    df = load_csv(file_path)\n",
        "\n",
        "    # Choose a column to analyze (replace 'ColumnName' with the actual column name)\n",
        "    selected_column = input(\"Enter the column to analyze: \")\n",
        "\n",
        "    # Analyze and save results\n",
        "    summary, plot_file, summary_file = parse_column_with_llm(df, selected_column)\n",
        "\n",
        "    print(f\"\\nFiles generated:\\nSummary: {summary_file}\")\n",
        "    if plot_file:\n",
        "        print(f\"Plot: {plot_file}\")\n",
        "    else:\n",
        "        print(\"No plot generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mRIDc2t0-Ho",
        "outputId": "920f1f78-44db-4753-dabb-8e0f6a07c4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   A_id      Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
            "0   0.0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
            "1   1.0 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
            "2   2.0 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
            "3   3.0 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
            "4   4.0  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
            "\n",
            "        Acidity Quality  \n",
            "0  -0.491590483    good  \n",
            "1  -0.722809367    good  \n",
            "2   2.621636473     bad  \n",
            "3   0.790723217    good  \n",
            "4   0.501984036    good  \n",
            "Enter the column to analyze: Quality\n",
            "\n",
            "Summary of 'Quality':\n",
            "       Quality\n",
            "count     4000\n",
            "unique       2\n",
            "top       good\n",
            "freq      2004\n",
            "\n",
            "Column 'Quality' is not numeric. Skipping plots.\n",
            "\n",
            "Summary and visualization saved successfully.\n",
            "\n",
            "Files generated:\n",
            "Summary: column_summary.txt\n",
            "No plot generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "R5T05qowEhnu",
        "outputId": "7da5cd6b-7b14-4e7b-f6f1-c3181a714291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.8.30)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=c256c2ffba242af44285712a6f4155a1f7b61300d634c0044840c9c0f9368d1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "serpapi"
                ]
              },
              "id": "d92d9dac7d5544c4b4d45f9f549fd779"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results --upgrade # Ensure the correct package name and upgrade if already installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x7sXnwwE4vp",
        "outputId": "fa35f957-e9a4-49fa-e6a5-9a50f522e525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch  # Change import statement\n",
        "\n",
        "# Web Search Function\n",
        "def web_search(query):\n",
        "    \"\"\"Perform a web search using SerpAPI.\"\"\"\n",
        "    search_params = {\n",
        "        \"q\": query,\n",
        "        \"api_key\": \",  # Replace with your SerpAPI key\n",
        "        \"engine\": \"google\"\n",
        "    }\n",
        "    search = GoogleSearch(search_params)\n",
        "    results = search.get_dict()\n",
        "\n",
        "    search_results = []\n",
        "    for result in results.get(\"organic_results\", []):\n",
        "        search_results.append({\n",
        "            \"title\": result.get(\"title\"),\n",
        "            \"link\": result.get(\"link\"),\n",
        "            \"snippet\": result.get(\"snippet\")\n",
        "        })\n",
        "\n",
        "    return search_results"
      ],
      "metadata": {
        "id": "uezEce1rEnxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Generate Queries Function\n",
        "def generate_queries(df, column_name, template):\n",
        "    \"\"\"Generate search queries for each entity using the custom template.\"\"\"\n",
        "    queries = []\n",
        "\n",
        "    # Check if the column exists in the DataFrame\n",
        "    if column_name not in df.columns:\n",
        "        print(f\"Error: Column '{Juiciness}' not found in the DataFrame.\")\n",
        "        return queries\n",
        "\n",
        "    # Iterate over the rows in the specified column\n",
        "    for entity in df[column_name]:\n",
        "        # Ensure the entity is a string and replace the placeholder in the template\n",
        "        if isinstance(entity, str):  # Check if the entity is a string\n",
        "            query = template.replace(\"{Juiciness}\", entity)\n",
        "        else:\n",
        "            query = template.replace(\"{Juiciness}\", str(entity))  # Convert to string if not already\n",
        "\n",
        "        queries.append(query)\n",
        "\n",
        "        # Debugging: Print the query for each entity\n",
        "        print(f\"Generated Query: {query}\")\n",
        "\n",
        "    return queries\n"
      ],
      "metadata": {
        "id": "a3KVXkqKC714"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# LLM Information Extraction Function\n",
        "def extract_information_with_llm(search_results, prompt_template):\n",
        "    \"\"\"Send search results to GPT-3 (or another LLM) for information extraction.\"\"\"\n",
        "    openai.api_key = replace your open ai key,
        "    extracted_info = []\n",
        "    for result in search_results:\n",
        "        prompt = prompt_template.replace(\"{Juiciness}\", result[\"title\"]) + \"\\n\\n\" + result[\"snippet\"]\n",
        "        try:\n",
        "            response = openai.Completion.create(\n",
        "                engine=\"text-davinci-003\",  # or another model\n",
        "                prompt=prompt,\n",
        "                max_tokens=100\n",
        "            )\n",
        "            extracted_info.append(response.choices[0].text.strip())\n",
        "        except Exception as e:\n",
        "            extracted_info.append(f\"Error: {str(e)}\")\n",
        "\n",
        "    return extracted_info\n"
      ],
      "metadata": {
        "id": "nTHneaTzC8e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display and Save Results Function\n",
        "def display_extracted_data(df, extracted_info):\n",
        "    \"\"\"Display extracted information in a user-friendly format and provide download options.\"\"\"\n",
        "    df['Extracted Information'] = extracted_info\n",
        "    print(\"Extracted Data Preview:\")\n",
        "    print(df[['Juiciness', 'Extracted Information']].head())\n",
        "\n",
        "    # Save the updated DataFrame to a CSV file\n",
        "    output_csv = \"extracted_information.csv\"\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"\\nData saved to {output_csv}\")\n",
        "    return output_csv\n"
      ],
      "metadata": {
        "id": "hNuPAlqfDIer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMKJX_J0HGSd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
